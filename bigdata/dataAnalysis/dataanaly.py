# -*- coding: utf-8 -*-
"""dataAnaly.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1t4rzSEsUHi5uQJfJBxuRyunoS19Tj2-P
"""

from google.colab import drive
drive.mount('/gdrive')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')

import random
import seaborn as sns
import matplotlib as mpl

from scipy import stats
from sklearn.metrics.pairwise import cosine_similarity as cs
from mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes

df_users = pd.read_csv('/gdrive/My Drive/Colab Notebooks/SSAFY/users.csv')  # 유저 데이터
df_problems = pd.read_csv('/gdrive/My Drive/Colab Notebooks/SSAFY/problems.csv')  # 문제 데이터
df_problems_solved = pd.read_csv('/gdrive/My Drive/Colab Notebooks/SSAFY/user_solved_problems_fixed.csv')  # 유저별 푼 문제 데이터
df_records_solved = pd.read_csv('/gdrive/My Drive/Colab Notebooks/SSAFY/user_lately_solved_problems2.csv')  # 유저별 최근 60개의 '맞혔습니다' 데이터

display(df_users)

display(df_problems)

df_problems[df_problems.averageTries == 7340]

df_problems[~df_problems.tags.isnull()]

display(df_problems_solved)

# NA 값이 있는지 확인
df_problems.isna().sum(axis=0)/22988

"""태그에 NA 값이 전체 데이터에서 약 31% 존재함. => prepocessing needed"""

df_problems[df_problems.tags.isna()==1]

# 문제 데이터의 통계
df_problems.describe()

"""averageTries의 max값이 6,847인 데이터는 확인이 필요해보임."""

# 문제 데이터의 각 컬럼의 고유값 개수 구하기
print('problemId 고유값:', df_problems.problemId.nunique())
print('level 고유값:', df_problems.level.nunique())
print('titleKo 고유값:', df_problems.titleKo.nunique())
print('tags 고유값: ', len(set(sum(df_problems.tags.apply(lambda x: str(x).split(',')).to_list(),[]))))

# 문제 데이터의 연속형 변수 컬럼 확인
# - accepted_user_count
fig, ax= plt.subplots(figsize=[8,8])
ax= sns.boxplot(df_problems.acceptedUserCount)
ax= sns.violinplot(df_problems.acceptedUserCount)

ax2 = plt.axes([0.6, 0.6, .2, .2], facecolor='w')
ax2= sns.boxplot(df_problems.acceptedUserCount, ax=ax2)
ax2.set_xlim([0,665])
ax2.set_title('zoom to mean')

print(df_problems.acceptedUserCount)

"""문제별 맞은 사람 수가 평균 값인 665 근처로 쏠려있음."""

# avergeTries
fig, ax= plt.subplots(figsize=[5,5])
ax= sns.boxplot(df_problems.averageTries)
ax= sns.violinplot(df_problems.averageTries)

df_problems[df_problems.averageTries == 6847]

"""문제 시도 횟수에서 이전에 보았던 것처럼 6,847인 이상치가 하나 존재함."""

fig, ax= plt.subplots(figsize=[5,5])
ax= sns.boxplot(df_problems[df_problems.averageTries!=6847].averageTries)
ax= sns.violinplot(df_problems[df_problems.averageTries!=6847].averageTries)

ax2 = plt.axes([0.6, 0.6, .2, .2], facecolor='w')
ax2= sns.boxplot(df_problems[df_problems.averageTries!=6847].averageTries, ax=ax2)
ax2.set_xlim([0,3])
ax2.set_title('zoom to mean')

"""이상치를 제거했을 때, 평균값인 2에 평균 시도 횟수가 몰려있음.

averageTries가 6847인 데이터는 제외하는게 좋을 것으로 보임.
"""

print('제거 전:', len(df_problems))
df_problems.drop(df_problems[df_problems.averageTries == 6847].index, axis=0, inplace=True)
print('제거 후:', len(df_problems))

# 유저가 맞힌 문제 수를 분석

def num(x):
    return len(str(x).split(','))

df_problems_solved['num']= df_problems_solved.problems.apply(num)
df_problems_solved[['id', 'num']]

df_problems_solved.num.describe()

"""유저가 푼 문제 수의 평균은 133개입니다."""

fig, ax= plt.subplots(figsize=[5,5])
ax= sns.boxplot(df_problems_solved.num)
ax= sns.violinplot(df_problems_solved.num)

ax2 = plt.axes([0.6, 0.6, .2, .2], facecolor='w')
ax2= sns.boxplot(df_problems_solved.num, ax=ax2)
ax2.set_xlim([0,363])
ax2.set_title('zoom to mean')

"""유저의 문제 풀이 수는 평균인 133개에 몰려있네요."""

# 가장 문제를 많이 푼 유저는?

df_problems_solved[df_problems_solved.num== 11226]

"""users에 기록된 koosaga의 solved_count인 11075와 값이 다르네요. 😮
  
이는 BOJ와 solved.ac에서 집계하는 문제 수의 차이, 부분 점수가 들어가는 100% 맞지 못한 문제 등 여러 요인으로 인한 것으로 보입니다.
"""

# 유저 데이터에서 문제를 하나도 풀지 않은 사람의 수는 몇 명?
print("문제를 한 번도 안 푼 사람의 수 :", len(df_users.loc[df_users['solved_count'] == 0]))

print(len(df_users))

"""약 2%(1.6815)의 유저가 문제를 하나도 풀지 않았음을 알 수 있음."""

# 문제의 알고리즘을 분류하는 태그의 종류 수 구하기
set_tags = set()
for tags in df_problems['tags'].dropna().values:
    for tag in tags.split(','):
        set_tags.add(tag)

print("tag의 종류 수 :", len(set_tags))

"""총 191개의 태그가 존재한다는 것을 알 수 있음."""

# 문제의 ID별로 제목, 풀린 횟수 그리고 레벨(티어)을 빠르게 읽을 수 있도록 dictionary 형태로 저장하기
id2title = dict() # 문제 id와 title을 딕셔너리로 저장
id2count = dict() # 문제 id별로 풀린 횟수를 세기 위한 딕셔너리 생성
id2level = dict() # 문제 id별로 레벨 딕셔너리
for i in tqdm(range(len(df_problems))):
    id2title[df_problems.iloc[i, 1]] = df_problems.iloc[i, 2]
    id2count[df_problems.iloc[i, 1]] = 0
    id2level[df_problems.iloc[i, 1]] = df_problems.iloc[i, 6]

# 채점을 허용하지 않아서 아예 처음부터 풀 수 없는 문제는 무엇일까?
# is_solvable == False인 것들 확인
non_solvable = df_problems.loc[df_problems['isSolvable'] == False]
non_solvable

"""304개의 문제가 풀 수 없는 것으로 나타남."""

# 아예 풀 수 없는 문제는 분석에서 제외

# isSolvable == False 인 문제는 제외
df_problems = df_problems.drop(index=non_solvable.index).reset_index(drop=True)
df_problems

# 문제 레벨(티어) 분석

# 문제 레벨 종류 확인하기
print(sorted(df_problems['level'].unique()))

"""0부터 30까지의 정수로 이루어져 있음."""

# 문제 레벨 분포 확인하기

level_cnt = df_problems['level'].value_counts().sort_index()

plt.figure(figsize=(15,5))
sns.barplot(x=level_cnt.index, y=level_cnt.values)

"""레벨이 0인 것이 너무 많음.
  
레벨이 0인 문제는 난이도가 매겨지지 않은 문제이므로 이를 제외하여 분포를 다시 그린다.
"""

# level이 0인 것을 제외한 후 다시 분포를 확인.
df_problems = df_problems.loc[df_problems['level'] != 0].reset_index(drop=True)

level_cnt = df_problems['level'].value_counts().sort_index()

plt.figure(figsize=(15,5))
sns.barplot(x=level_cnt.index, y=level_cnt.values)

"""난이도가 매겨진 문제들은 중간 부분의 레벨에 많이 분표해있음.
  
가장 많이 분포한 레벨은 브론즈 2이고, 그 외의 골드4와 골드 3에도 많이 분포한 것을 볼 수 있음.
  
즉, 중간 정도의 난이도를 가진 문제들이 대체로 많이 난이도가 매겨졌다고 볼 수 있음.
"""

# 유저별 푼 문제 분석

# 유저들이 어떠한 문제를 많이 풀었는지, 어떤 태그 위주의 문제를 주로 풀었는지 분석


# 문제별로 풀린 횟수 계산
for i in tqdm(range(len(df_problems_solved))):
    try:
        pro = list(df_problems_solved.iloc[i, 2].split(','))
        for j in pro:
            j = int(j)
            id2count[j] += 1
    except:
        pass

# 문제별로 풀린 횟수를 계산한 데이터프레임
# count 컬럼이 풀린 횟수.
df_problem_count = pd.DataFrame({'problem_id' : id2count.keys(), 'count' : id2count.values()})
df_problem_count['title'] = df_problem_count['problem_id'].apply(lambda x : id2title[x])
df_problem_count['level'] = df_problem_count['problem_id'].apply(lambda x : id2level[x])
df_problem_count.sort_values('count', inplace=True, ascending=False)
df_problem_count[:10]

# 어떤 태그가 많이 풀렸나?

# isSolvable == True, level > 0인 문제들의 태그 분포 확인
dict_tag_cnt = {i:int(j) for i, j in zip(set_tags, np.zeros(len(set_tags)))}
for i in tqdm(range(len(df_problems))):
    tags = df_problems.iloc[i, 6]
    try:
        for tag in tags.split(','):
            dict_tag_cnt[tag] += 1
    except:
        pass

# 많이 풀린 tag 횟수에 관한 데이터프레임
# tag_count 컬럼이 각 tag별 풀린 횟수

df_tag_count = pd.DataFrame({'tag' : dict_tag_cnt.keys(), 'tag_count' : dict_tag_cnt.values()})
df_tag_count.sort_values('tag_count', ascending=False, inplace=True)
df_tag_count.reset_index(drop=True, inplace=True)
df_tag_count[:10]

"""추후 대표 태그를 선정해 input으로 사용해도 좋을 것이라고 판단함."""

# 유저가 최근에 어떠한 문제들을 많이 풀었는지?

# 모든 유저가 최근에 풀었던 문제 종류 수
print("모든 유저가 최근에 풀었던 문제 종류 수 :", df_records_solved['problem'].nunique(), "개")

# 유저가 같은 문제에 관해 "맞았습니다" 제출을 여러 번 했으면 가장 최근 풀었던 기록만 남겨둘게요.

# 사용자가 똑같은 문제를 풀었다면 최근에 풀었던 기록만 남겨둠.
df_records_solved = df_records_solved.drop_duplicates(subset=('handle', 'problem')).reset_index(drop=True)
df_records_solved

# 최근 "맞았습니다" 기록에서 문제를 10개 이상 푼 유저의 수는 몇 명일까요?

group_records_solved = df_records_solved.groupby('handle')['problem'].count()
print("문제를 10개 이상 푼 유저의 수 :", len(group_records_solved[group_records_solved >= 10]), '명')

"""만약 "맞았습니다" 데이터를 사용할 수 있으면 약 88%의 유저는 최근에 푼 10개 이상의 문제를 기반으로 좀 더 개인화된 문제를 추천할 수 있겠네요.
  
하지만 최근 채점 데이터는 웹 스크레이핑이 불가하므로 추천 모델링에는 사용하기가 어려워보입니다. 😢
  
나중에 기회가 되면 sequential model 제작에 도전해 봐야겠네요. 🧐
"""

# 비슷한 문제 탐색 방법 테스트
# 어떤 한 문제와 유사한 문제는 어떻게 찾는 게 좋을까? 다양한 방법으로 시도해보기
# 예시로 문제 1027번과 유사한 문제를 다양한 방법으로 찾아보기

df_problems.loc[df_problems['problemId'] == 1027]

# 1. cosine 유사도

# 코사인 유사도 기반
df_for_test = df_problems[['problemId', 'titleKo', 'level', 'averageTries']]
for i in list(list(set_tags)):
    df_for_test[i] = 0

for i in tqdm(range(len(df_problems))):
    tags = df_problems.iloc[i, 6]
    try:
        for tag in tags.split(','):
            df_for_test.iloc[i, list(df_for_test.columns).index(tag)] += 1
    except:
        pass

temp = df_for_test.iloc[:, 2:].values
sim = cs(temp, temp)

sim_scores = list(enumerate(sim[27]))
sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)
sim_scores = sim_scores[1:20]
print(sim_scores)

# 구한 cosine 유사도 값이 가장 높은 문제 정보를 확인

idx = np.array(sim_scores)[:, 0]
df_for_cos = df_for_test.iloc[idx]
df_for_cos

# 유클리드 거리 기반으로 유사한 문제 구하기


# 그전에 두 좌표 사이의 거리를 구하는 식을 함수로 정의
def dist(x,y):
    return np.sqrt(np.sum((x-y)**2))

# 유클리드 거리 기반 유사한 문제 구하기
problem_idx = 27
list_dist = []
for i, j in tqdm(enumerate(temp)):
    list_dist.append((i, dist(temp[problem_idx], j)))

list_dist = sorted(list_dist, key = lambda x : x[1])
list_dist = list_dist[:20]
print(list_dist)

# 문제간 거리가 가까울수록 유사한 문제
df_for_euclidean = df_for_test.iloc[np.array(list_dist)[1:,0]]
df_for_euclidean

"""코사인 유사도보다는 유클리드 기반으로 거리가 가까운 문제를 구한 것의 레벨이 전반적으로 비교 대상인 1027번 문제의 레벨과 비슷한 것을 볼 수 있습니다."""

df_for_cos[(df_for_cos.bruteforcing == 1) & (df_for_cos.geometry == 1) & (df_for_cos.math == 1)]

df_for_euclidean[(df_for_euclidean.bruteforcing == 1) & (df_for_euclidean.geometry == 1) & (df_for_euclidean.math == 1)]

"""그러나 문제 1027번의 태그와 가장 유사하게 추천된 방법은 코사인 유사도.
두 방법을 적절히 조화해서 추천을 하든가, 아니면 레벨과 태그에 관해 필터링 할 때 각 경우에 관해 좀 더 나은 성능을 보이는 방법을 고려 가능. 
"""

# 푼 문제가 없지만 경험치 또는 티어가 존재하는 유저

# 푼 문제 수가 0인 유저를 다시 한 번 학인해 봄
df_users[df_users.solved_count == 0]

print('푼 문제 수가 0인 유저(1,510명) 중 rating이나 exp가 0이 아닌 유저들:',len(df_users[(df_users.solved_count == 0) & ((df_users.rating !=0)|(df_users.exp !=0))]))

"""1,510명 중 rating이나 exp가 0이 아닌 유저들은 19명 입니다.

해당 유저들은 데이터를 받아오는 solved.ac에서 제재당한 유저일 가능성이 큽니다.
대표적인 solved.ac에서 사용자를 제재하는 경우 : 부정행위로 문제를 맞춘 경우
이와 비슷한 경우로 발생한 데이터로는 푼 문제 수가 0개가 아니지만 rating과 exp가 모두 0인 유저들이 데이터로 남아있습니다.
"""

# 1,510명은 푼 문제에 대한 정보가 존재하지 않으므로 해당 유저들은 df_users에서 제거

print('solved_count가 0인 유저들 제거 전:', len(df_users))
df_users.drop(df_users[df_users.solved_count == 0].index.to_list(), inplace=True)
print('solved_count가 0인 유저들 제거 전:', len(df_users))

df_users[df_users.solved_count == 0]

# 유저 클래스 분석

# 유저 클래스 통계를 확인
df_users.user_class.describe()

# class가 0인 유저를 살펴봄

df_users[df_users.user_class==0]

# 푼 문제 수가 0이 아니지만 rating과 exp(경험치)가 모두 0인 유저들

print('class가 0인 유저들 중 rating과 exp가 모두 0인 유저:',len(df_users[(df_users.user_class==0) & (df_users.rating ==0) & (df_users.exp ==0)]))

df_problems_solved[df_problems_solved.handle.isin(list(df_users[(df_users.user_class==0) & (df_users.rating ==0) & (df_users.exp ==0)]['handle']))]

"""이 11명의 유저들 중엔 problems_solved에 기록된 유저(6명)도 있고 아닌 유저도 있습니다."""

# 유저의 클래스 분포를 확인

plt.subplots(figsize=(7,7))
df_users.user_class.astype('str')
ax=sns.barplot(df_users.user_class.astype('str').value_counts().index,df_users.user_class.astype('str').value_counts())

for p in ax.patches:
    height = p.get_height()
    ax.text(p.get_x() + p.get_width() / 2., height + 3.5, height, ha = 'center', size = 9)

"""
class가 높아질수록 그에 해당하는 유저 수도 감소."""

# 유저 티어 분석

# 유저 티어 통계를 살펴봄.
df_users.tier.describe()

plt.subplots(figsize=(10,7))
df_users.tier.astype('str')
ax=sns.barplot(df_users.tier.astype('str').value_counts().index,df_users.tier.astype('str').value_counts(), order= df_users.tier.astype('str').unique())

"""user_class와 달리 tier는 0과 6-7(실버 1~2) 티어에 유저들이 많이 분포함.
  
14, 15 티어에 또한 유저들이 많이 분포.
"""

# 문제 레벨별 데이터 분석

# 문제 레벨별 문제 평균 시도 횟수
plt.figure(figsize=(15,5))
graph = sns.barplot(x=df_problems.level, y=df_problems.averageTries)
graph.axhline(np.mean(df_problems.averageTries))
plt.show()

# 문제 레벨별 맞힌 사람 수의 분포

plt.figure(figsize=(15,5))
graph = sns.barplot(x=df_problems.level, y=df_problems.acceptedUserCount)
graph.axhline(np.mean(df_problems.averageTries))
plt.show()

# 레벨이 1에서 3인 것을 제외하고 조회
tmp = df_problems.groupby('level')['acceptedUserCount'].mean()[df_problems.groupby('level')['acceptedUserCount'].mean() < 2000]

plt.figure(figsize=(15,5))
graph = sns.barplot(x=tmp.index, y=tmp.values)
plt.show()

"""대체로 입문 단계인 하위권 문제가 많이 풀렸고, 하위권 문제를 제외하여도 문제의 난이도가 높아질 수록 맞힌 유저의 수는 급격히 감소."""

# 문제 레벨별 태그 분석.

# 각 문제 레벨별 태그 종류의 수를 집계.


# tag에 nan 값이 있는 행들 삭제
new_df_problems = df_problems.dropna()

# 각 레벨별 태그 유형별 개수 저장
tags_per_level = {}

for x in df_problems.level.unique():
    levelx_tags = ','.join(new_df_problems[new_df_problems.level == x].tags.values).split(',')
    levelx_tags = pd.DataFrame(pd.Series(levelx_tags).value_counts())
    levelx_tags.reset_index(inplace=True, drop=False)
    levelx_tags.columns = ['tag', 'level'+str(x)]
    
    tags_per_level["level" + str(x)] = levelx_tags

# 레벨 1의 태그별 분포

# level1인 경우
tags_per_level['level1']

# 문제의 레벨별로 속해있는 태그 수

level_tags = pd.DataFrame(columns={'level', 'level_tag_count'})

for i in range(1, 31):
    level_tags = level_tags.append({'level': 'level'+str(i), 'level_tag_count': len(tags_per_level['level'+str(i)])}, ignore_index=True)
    
plt.figure(figsize=(15,5))
graph = sns.barplot(x=level_tags.level, y=level_tags.level_tag_count)

for item in graph.get_xticklabels():
    item.set_rotation(45)

plt.show()

# 태그별 문제 레벨 분석

# 각 태그별로 각 레벨에 몇 번 등장하는지 구하기


# 각 태그별 모든 레벨 값을 merge한다.
tags_all_level = pd.merge(tags_per_level['level1'], tags_per_level['level2'], on='tag', how='outer')

for i in range(3, 31):
    tags_all_level = pd.merge(tags_all_level, tags_per_level['level'+str(i)], on='tag', how='outer')

tags_all_level.fillna(0, inplace=True)
tags_all_level.head()

# 각 태그별로 각 레벨에 어떻게 분포되어 있는지를 확인

# 각 레별별 태그의 비율 분포를 확인하기 (상대비교를 위해 각 레벨의 태그 개수를 문제 수 만큼 나누기)
tags_all_level_ratio = tags_all_level.copy()

# 각 레벨별 문제 수 정리
level_ques = pd.DataFrame(new_df_problems.level.value_counts())
level_ques.reset_index(inplace=True, drop=False)
level_ques.columns = ['level', 'nums']

# 각 레벨의 태그 개수에서 문제 수 나누기
for i in range(1, 31):
    tags_all_level_ratio['level'+str(i)] = tags_all_level['level'+str(i)]/level_ques[level_ques['level'] == i].nums.values[0]

tags_all_level_ratio

# 가장 대표적인 태그인 data_structures를 예시로 상위 레벨에서의 분포로 확인

tag_name = 'data_structures'

plt.figure(figsize=(5,5))

x = tags_all_level_ratio[tags_all_level_ratio['tag'] == tag_name].T.iloc[1:,:]
x.columns = ['ratio']
x = x.sort_values('ratio', ascending=False)[:10]

ratio = x['ratio'].values
labels = x.index

#explode = [0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05]

plt.pie(ratio, labels=labels, autopct='%.1f%%')#, explode=explode)
plt.show()

"""대표적으로 기본이 되는 태그인 data_structures는 난이도별 등장 분포가 골고루 나오기도 함."""

# 각 문제의 태그 종류 수 분석

# 각 문제에 태그가 몇 종류 등장하는지를 확인

problem_tags = df_problems.tags.str.split(',')
problem_tags.fillna('0', inplace=True)
df_problems['tag_num'] = problem_tags.apply(lambda x: len(x))
df_problems.head()

# 태그가 없는 문제도 tag_num이 1로 집계되는 현상 없애기

# null인 인덱스의 태그 값 제거
tags_null_idx = df_problems[df_problems.tags.isnull()].index
df_problems.loc[tags_null_idx, 'tag_num'] -= 1

# 문제별 태그 종류 수 분포

sns.displot(df_problems.tag_num, bins=100)

"""대체로 문제별로 두 개의 태그가 가장 많이 등장하는 것으로 보이네요."""

# 라이벌과 역라이벌 수 분석

# 유저별 라이벌과 역라이벌 수에 관한 통계 살펴봄

df_users.rival_count.describe()

df_users.reverse_rival_count.describe()

# 얼마나 많은 유저가 solved.ac의 라이벌 기능을 이용하고 있는지?

print('rival 수가 0인 유저 비율:',sum(df_users.rival_count==0)/len(df_users))
print('reverse_rival 수가 0인 유저 비율:',sum(df_users.reverse_rival_count==0)/len(df_users))
print('reverse_rival과 rival 수가 0인 유저 비율:',sum((df_users.reverse_rival_count==0) & (df_users.rival_count==0))/len(df_users))

"""전체 유저 중 약 83%가 현재 제공되고 있는 라이벌 기능을 사용하지 않고 있음. 
대다수의 유저가 라이벌 기능을 사용하지 않는 만큼, 라이벌 추천 서비스를 제공하면 조금이나마 라이벌 기능을 활성화시킬 수 있지 않을까요?

🔖 라이벌 관련 실험 및 결과
  
라이벌에 관해 분석한 데이터를 바탕으로 가설을 세우고 검증해볼게요.
이를 통해 어떤 방법으로 추천 모델을 만들어야 할지, 필터링은 어떤 식으로 해야할지 고민해 봅시다.
"""

# 가설 1: 라이벌이 있는 유저들은 그렇지 않은 유저들에 비해 문제를 더 많이 풉니다.

df_check_rival = df_users.copy()
df_check_rival['has_rival'] = 'NO'

idx = df_check_rival[df_check_rival.rival_count >= 1].index
df_check_rival.loc[idx, 'has_rival'] = 'YES'
df_check_rival

sns.barplot(x='has_rival', y = 'solved_count', data=df_check_rival)

"""rival이 있는 유저들이 rival이 없는 유저들에 비에 2배 이상 문제를 더 많이 푸네요.
  
역시 라이벌 기능을 이용하고 있는 사람은 알고리즘 문제를 대체로 더 많이 푸는 것으로 보입니다.
"""

df_check_rival['has_rival'] = np.where(df_check_rival['has_rival']=='YES', 1 ,0)
stats.pointbiserialr(df_check_rival['has_rival'], df_check_rival['solved_count']).correlation

"""상관관계가 0.2273로 약한 양의 상관관계를 보여주네요.
  
[정리]
  
rival의 여부와 문제 푸는 횟수는 약한 양의 상관관계를 보입니다.
  
rival이 있는 유저들이 rival이 없는 유저들에 비에 2배 이상의 문제를 더 많이 풉니다.
  
→ rival이 있으면 유저들이 문제를 더 많이 풉니다.
  
→ rival을 등록할 수 있도록 적절한 라이벌 추천해주면 유저들이 문제를 더 많이 풀어서 개인 실력 향상과 백준 사이트의 활성화에 도움을 줄 것으로 보입니다. 🥳
"""

# 가설 2: 라이벌이 많을수록 문제를 더 많이 풉니다.

# 가설 배경: 적절한 추천 라이벌 수를 찾기 위해

df_check_rival

df_has_rival = df_check_rival[df_check_rival.has_rival == 1]
df_has_rival

# rival_count와 solved_count와의 관계성을 시각화.

df_for_pairplot = df_has_rival[['solved_count', 'rival_count']]
sns.pairplot(df_for_pairplot, kind='reg', height=4)  # 페어플롯 작성

"""라이벌 수와 푼 문제 수 간의 약한 관계성이 있어 보입니다."""

# 통계적 검정(피어슨 상관계수 검정)을 통해 구체적인 상관관계 파악. *******************************************************************
stats.pearsonr(df_has_rival.rival_count, df_has_rival.solved_count)

"""상관관계: 
  
p-value: 
  
    
[정리]
  
라이벌이 많을수록 문제를 푸는 횟수와 약한 상관관계를 보입니다.
  
적절히 큰 라이벌 수를 정하면 문제 푸는 횟수가 늘어날 것으로 보입니다.
"""

# 실험 1: 라이벌이 있는 유저들의 평균적인 라이벌 수는 몇 명일까요?

# 실제 데이터의 형상을 보기 위해 바이올린 플롯으로 시각화. https://junklee.tistory.com/9
plt.figure(figsize=(10,5))
sns.violinplot(x='rival_count', data=df_has_rival)

# 라이벌을 100명 이상으로 정한 유저들 확인
df_has_rival[df_has_rival.rival_count >=100]

# outside point를 제외한 바이올린 플롯의 부분 확대
plt.figure(figsize=(10,5))
fig = sns.violinplot(x='rival_count', data=df_has_rival)
fig.set_xlim([-5, 15])
#fig.set_ylim([-0.5, 0.5])

# 평균적인 rival 수 확인
print("평균 rival 수:", round(np.mean(df_has_rival.rival_count), 2),'명')

"""[정리]
  
outside point: 20명 이상
  
upper adjacent values(상위 근접 값: 해당 값보다 크면 이상치로 판별 가능): 8명
  
median: 약 2.5명
  
mean 약 3.74명
  
→ rival 수는 2~3명 추천으로 잡아도 될 것으로 보입니다. 
"""

# 실험 2: 라이벌로 지정할 만한 유저를 찾아볼까요?
# 기준: 나와 비슷한 실력의 유저 또는 나보다 실력이 조금 더 높은 유저

df_users[df_users.handle == '1017hana']

# tier 9(Silver II) 중  1017hana의 라이벌 찾아보기
df_tier_9 = df_users[df_users.tier == 9]
target_user = '1017hana' # 예시로 쓸 타겟 유저

df_tier_9

# 1. 타겟 유저와 같거나 한 단계 높은 티어로 실력 범위를 줄입니다.

print('후보수 전:', len(df_users)-1)

df_tier_10 = df_users[df_users.tier == 10]
df_candi_by_tier = pd.concat([df_tier_9, df_tier_10], axis=0)

print('후보수 후:', len(df_candi_by_tier)-1)
df_candi_by_tier[df_candi_by_tier.tier == 9]

df_candi_by_tier[df_candi_by_tier.tier == 10]

df_candi_by_tier.head()

# 2. rating_by_problems_sum(푼 문제의 난이도 합으로 계산한 사용자의 레이팅)이 비슷한 유저들로 범위 줄이기

t_rating_b_problems_sum = df_tier_9[df_tier_9.handle == target_user].rating_by_problems_sum.values[0] 
print(target_user+'의 rating_by_problems_sum:', t_rating_b_problems_sum)

# target user가 속한 티어와 한 단계 높은 티어와의 rating_by_problems_sum 분포 확인
# 초록색 점선: target user의 rating_by_problems_sum

plt.figure(figsize=(10,5))
sns.violinplot(x="tier", y="rating_by_problems_sum", data=df_candi_by_tier)
plt.axhline(y=t_rating_b_problems_sum, color='g', linestyle='--')

up_target_user = 'thqjarl' # 예시로 쓸 타겟 유저
up_rating_b_problems_sum = df_tier_10[df_tier_10.handle == up_target_user].rating_by_problems_sum.values[0]
print('tier10의 rating_by_problems_sum:', up_rating_b_problems_sum)

plt.figure(figsize=(10,5))
sns.violinplot(x="tier", y="rating_by_problems_sum", data=df_candi_by_tier)
plt.axhline(y=up_rating_b_problems_sum, color='g', linestyle='--')

"""타겟 유저는 현재 속한 티어에서 중상위권 유저임을 알 수 있습니다.
  
한 단계 높은 레벨에서도 하위권에 속함을 알 수 있습니다.
  
타겟 유저보다 rating_by_problems_sum이 100(임시) 높은 유저로 바운더리 정하는 게 좋아 보입니다. 
"""

# 타겟 유저의 rating_by_problems_sum <= 후보군 rating_by_problems_sum <= 타겟 유저의 rating_by_problems_sum + 100
threshold = 100

print('후보수 후:', len(df_candi_by_tier)-1)
df_candi_by_rbps = df_candi_by_tier[(df_candi_by_tier.rating_by_problems_sum >= t_rating_b_problems_sum) & (df_candi_by_tier.rating_by_problems_sum <= t_rating_b_problems_sum+threshold)]
print('후보수 후:',len(df_candi_by_rbps)-1)
df_candi_by_rbps.head()

"""# **PASS Processing df_problems_solved**"""

df_usp = pd.merge(df_users, df_problems_solved, on='handle')
# null이 담긴 사용자 제거
df_usp = df_usp[~df_usp.problems.isnull()]
df_usp

# 3. 타겟 유저 푼 태그 기반으로 나의 부족한 점을 더 많이 푼 유저 찾기

df_problems = df_problems[df_problems.level != 0]
# not_solvable == False만
df_problems = df_problems[df_problems.isSolvable == True]
# tag가 nan인 문제 제거
df_problems = df_problems[~df_problems.tags.isnull()]
df_problems.head()

# 후보 유저들만 추리기  PASS Processing df_problems_solved
candi_users = df_candi_by_rbps.handle.values
df_usp_candi = df_usp[df_usp.handle.isin(candi_users)]
df_usp_candi

# 필요한 태그 칼럼 정리하기
tags = ['math', 'implementation', 'greedy', 'string', 'data-structures', 'geometry', 'dp', 'dfs', 'bfs']
for x in tags:
    df_usp_candi[x] = 0

df_usp_candi

def class_user_tag(df):    
    # 특정 유저가 푼 problems 구하기
    for user in tqdm(candi_users):
        if (len(df[df.handle == user].problems.values) == 0):
            continue;
        df_one_user_problems = df[df.handle == user].problems.values[0]
        one_user_problems = df_one_user_problems.split(',')

        # 특정 유저가 푼 problems의 태그 값들 구하기
        user_tag = []
        for i in range(len(one_user_problems)):
            one_problem = df_problems[df_problems.problemId == int(one_user_problems[i])]
            one_problem_tags = ','.join(one_problem.tags.values).split(',')
            user_tag.extend(one_problem_tags)

        # 특정 유저가 푼 태그별 개수 구하기: e.g. counts = {'arithmetic': 1, 'implementation': 3, 'math': 10, ... }
        counts = dict()
        for i in user_tag:
            counts[i] = counts.get(i, 0) + 1

        # 특정 유저의 태그 칼럼에 각 태그 값 넣기
        idx = df[df['handle'] == user].index
        for k, v in counts.items():
            if k in df.columns:
                df.loc[idx, k] = v

    return df

df_candi_with_tags = class_user_tag(df_usp_candi)

# 라이벌 유저군들의 푼 태그 수와 타겟 유저가 푼 태그 수 확인
df_target_candi_tags = pd.DataFrame(df_candi_with_tags.sum(axis=0)[tags]).reset_index()
df_target_candi_tags.columns = ['tags', 'num']
df_target_candi_tags.num = df_target_candi_tags.num/len(df_candi_with_tags)

target_tags_values = df_candi_with_tags[df_candi_with_tags.handle == target_user][tags].values
df_target_candi_tags['target'] = target_tags_values[0]
df_target_candi_tags

# 라이벌 유저군 보다 내가 부족한 태그 부분 확인
bar_width = 0.35
alpha = 0.5
index = np.arange(9)
label = df_target_candi_tags.tags

plt.figure(figsize=(15,5))
p1 = plt.bar(index, df_target_candi_tags.target, bar_width, 
             color='b', alpha=alpha,label=target_user)

p2 = plt.bar(index + bar_width, df_target_candi_tags.num, bar_width, 
            color='r', alpha=alpha,label='mean_users')

plt.title('Compare solved tags of '+target_user+' and mean of users in same user_class', fontsize=15)
plt.ylabel('tags #', fontsize=10)
#plt.xlabel('tags', fontsize=18)
plt.xticks(index, label, fontsize=15, rotation=45)
plt.legend((p1[0], p2[0]), (target_user, 'rival group users'), fontsize=15)
plt.show()

"""타겟 유저는 라이벌 유저군보다 Implementation, math, (string, geometry) 를 적게 

풀었습니다.
  
greedy, dp, dfs, bfs는 더 많이 풀었음을 알 수 있네요. 😎
"""

need_more_tags = df_target_candi_tags[df_target_candi_tags.num > df_target_candi_tags.target].tags.values
need_more_tags

# 라이벌 유저군들 중에서 내가 부족한 부분을 더 공부한 유저 확인
tag_candi = df_candi_with_tags.copy()

print('후보수 후:',len(df_candi_by_rbps)-1)
for x in need_more_tags:
    tag_candi = tag_candi[tag_candi[x] >= tag_candi[tag_candi.handle==target_user][x].values[0]]
    print(x+' 태그 필터링 후: ', end='')
    print(len(tag_candi)-1)

# 4. 후보군들 중 랜덤으로 3명을 추출해봅니다.

seed = 42

fin_candi = tag_candi[tag_candi.handle != target_user].reset_index()

seq = list(np.arange(len(fin_candi)))
random.seed(seed)
target_rivals_3 = random.sample(seq, 3)
target_rivals_3

fin_candi.iloc[target_rivals_3]

# 라이벌 유저군 보다 내가 부족한 태그 부분 확인
bar_width = 0.35
alpha = 0.5
index = np.arange(9)
label = df_target_candi_tags.tags

for i in range(3):
    rival_data = fin_candi.iloc[target_rivals_3[i]]
    plt.figure(figsize=(15,5))
    p1 = plt.bar(index, tag_candi[tag_candi.handle == target_user][tags].values[0], bar_width, 
                color='b', alpha=alpha,label=target_user)

    p2 = plt.bar(index + bar_width, rival_data[tags].values, bar_width, 
                color='r', alpha=alpha,label='mean_users')

    plt.title('Compare solved tags of '+target_user+' and their rival', fontsize=15)
    plt.ylabel('tags #', fontsize=10)
    #plt.xlabel('tags', fontsize=18)
    plt.xticks(index, label, fontsize=15, rotation=45)
    plt.legend((p1[0], p2[0]), (target_user, 'rival: '+rival_data.handle), fontsize=15)
    plt.show()

"""비슷한 라이벌과 비교했을 때 타겟 유저가 상대적으로 덜 푼 태그 유형이 보이네요.

## 💡 유저와 문제풀이 관련 실험 및 결과
  
유저와 문제 풀이에 관해 분석한 데이터를 바탕으로 가설을 세우고 검증해볼게요.

이를 통해 어떤 방법으로 추천 모델을 만들어야 할지, 필터링은 어떤 식으로 해야할지 고민해 봅시다.

가설. 유저 클래스별 많이 푸는 태그 유형이 있을 것입니다.
  
우선 unique한 태그 값을 구하여 새로운 칼럼으로 추가해 봅시다. 😏
"""

unique_tags = []
all_tags = df_problems.tags.str.split(',').values

for x in all_tags:
    unique_tags.extend(x)
    
unique_tags = set(unique_tags)

# 새로운 칼럼으로 추가하기
tmp = df_usp.copy()

for x in unique_tags:
    tmp[x] = 0
tmp

sorted(list(tmp.user_class.unique()))

def class_user_tag(user_class):

    users = tmp[tmp.user_class == user_class].handle.values
    
    # 특정 유저가 푼 problems 구하기
    for user in tqdm(users):
        df_one_user_problems = df_usp[df_usp.handle == user].problems.values[0]
        one_user_problems = df_one_user_problems.split(',')

        # 특정 유저가 푼 problems의 태그 값들 구하기
        user_tag = []
        for i in range(len(one_user_problems)):
            if one_user_problems[i] == '':
              continue
            one_problem = df_problems[df_problems.problemId == int(one_user_problems[i])]
            one_problem_tags = ','.join(one_problem.tags.values).split(',')
            user_tag.extend(one_problem_tags)

        # 특정 유저가 푼 태그별 개수 구하기: e.g. counts = {'arithmetic': 1, 'implementation': 3, 'math': 10, ... }
        counts = dict()
        for i in user_tag:
            counts[i] = counts.get(i, 0) + 1

        # 특정 유저의 태그 칼럼에 각 태그 값 넣기
        idx = tmp[tmp['handle'] == user].index
        for k, v in counts.items():
            tmp.loc[idx, k] = v

    return tmp

# 클래스 10인 유저가 많이 푼 태그 목록
class_num = 10

tmp_10 = class_user_tag(class_num)
tags_10_sum = pd.DataFrame(tmp_10[tmp_10.user_class == class_num].sum(axis=0)[unique_tags]).reset_index()
tags_10_sum.columns = ['tag', 'num']
tags_10_sum = tags_10_sum.sort_values('num', ascending=False).reset_index(drop=True)
tags_10_sum#.head()

# 클래스 6인 유저가 많이 푼 태그 목록
class_num = 6

tmp_6 = class_user_tag(class_num)
tags_6_sum = pd.DataFrame(tmp_6[tmp_6.user_class == class_num].sum(axis=0)[unique_tags]).reset_index()
tags_6_sum.columns = ['tag', 'num']
tags_6_sum = tags_6_sum.sort_values('num', ascending=False).reset_index(drop=True)
tags_6_sum.head(10)

# 클래스 3인 유저가 많이 푼 태그 목록
class_num = 3

tmp_3 = class_user_tag(class_num)
tags_3_sum = pd.DataFrame(tmp_3[tmp_3.user_class == class_num].sum(axis=0)[unique_tags]).reset_index()
tags_3_sum.columns = ['tag', 'num']
tags_3_sum = tags_3_sum.sort_values('num', ascending=False).reset_index(drop=True)
tags_3_sum.head(10)

# 클래스 0인 유저가 많이 푼 태그 목록
class_num = 0

tmp_0 = class_user_tag(class_num)
tags_0_sum = pd.DataFrame(tmp_0[tmp_0.user_class == class_num].sum(axis=0)[unique_tags]).reset_index()
tags_0_sum.columns = ['tag', 'num']
tags_0_sum = tags_0_sum.sort_values('num', ascending=False).reset_index(drop=True)
tags_0_sum.head(10)

"""유저별 수준과 tag는 상관관계가 있다고 보았고, tag 정보를 유저가 푸는 문제를 파악하는데 사용할 수 있을 것으로 판단했습니다. 🙂

실험: 같은 클래스 내 태그별 평균적으로 푼 횟수와 한 유저가 푼 횟수를 비교해봅시다.
  
유저 클래스가 10인 유저를 선정해서 분석해봅시다.
"""

def one_user_tag(user):
    df_one_user_problems = df_usp[df_usp.handle == user].problems.values[0]
    one_user_problems = df_one_user_problems.split(',')

    # 특정 유저가 푼 problems의 태그 값들 구하기
    user_tag = []
    for i in range(len(one_user_problems)):
        one_problem = df_problems[df_problems.problemId == int(one_user_problems[i])]
        one_problem_tags = ','.join(one_problem.tags.values).split(',')
        user_tag.extend(one_problem_tags)

    # 특정 유저가 푼 태그별 개수 구하기: e.g. counts = {'arithmetic': 1, 'implementation': 3, 'math': 10, ... }
    counts = dict()
    for i in user_tag:
        counts[i] = counts.get(i, 0) + 1
    # 특정 유저의 태그 칼럼에 각 태그 값 넣기
    #idx = tmp[tmp['handle'] == user].index
    #for k, v in counts.items():
    #    tmp.loc[idx, k] = v

    return counts

df_usp[df_usp.user_class == 10].head()

# 랜덤으로 뽑은 arnold518 핸들을 지닌 유저를 분석해볼게요.

user_name = 'arnold518'
user_counts = one_user_tag(user_name)

user_10_tag = tags_10_sum.copy()
user_10_tag['user'] = 0

for k, v in user_counts.items():
    idx = user_10_tag[user_10_tag.tag == k].index
    user_10_tag.loc[idx, 'user'] = v

user_10_tag.num = user_10_tag.num / len(df_usp[df_usp.user_class == 10])
user_10_tag

top10_user_10_tag = user_10_tag.head(10)

bar_width = 0.35
alpha = 0.5
index = np.arange(10)
label = top10_user_10_tag.tag

plt.figure(figsize=(15,5))
p1 = plt.bar(index, top10_user_10_tag.user, bar_width, 
             color='b', alpha=alpha,label=user_name)

p2 = plt.bar(index + bar_width, top10_user_10_tag.num, bar_width, 
            color='r', alpha=alpha,label='mean_users')

plt.title('Compare solved tags of '+user_name+' and mean values of users in same user_class', fontsize=15)
plt.ylabel('tags #', fontsize=10)
#plt.xlabel('tags', fontsize=18)
plt.xticks(index, label, fontsize=15, rotation=45)
plt.legend((p1[0], p2[0]), (user_name, 'same class users'), fontsize=15)
plt.show()

"""arnold518은 같은 클래스 내 유저들에 비해 implementation, string, bruteforcing이 현저히 적음을 알 수 있습니다.
  
나중에 같은 Class 내 다른 유저들의 풀이 이력과 비교하여 유저가 많이 풀지 않은 tag 문제 위주로 추천하는 방법을 떠올려볼 수 있겠네요. 🤔
"""